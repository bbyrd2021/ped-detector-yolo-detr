{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf4f14-539f-4e71-ac84-0d0e25fa15bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install (quiet to keep logs clean)\n",
    "!pip -q install ultralytics==8.* roboflow pyspark\n",
    "\n",
    "# core imports\n",
    "import os, time, json, glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac28f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Project Configuration\n",
    "# ============================================\n",
    "\n",
    "# ----- experiment configuration -----\n",
    "RUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "PERSON_ONLY = True             # keep only 'person' class (COCO id=0)\n",
    "IMG_SIZE     = 640\n",
    "CONF_THRESH  = 0.25\n",
    "MAX_IMAGES   = None            # set small int while testing (e.g., 100)\n",
    "\n",
    "# ----- directory structure (based on your project tree) -----\n",
    "ROOT          = Path.cwd()                           # current project root\n",
    "DATA_DIR      = ROOT / \"data\"                        # raw dataset directory\n",
    "DERIVED_DIR   = ROOT / \"derived\" / \"caltech_yolo\"    # derived local data\n",
    "RUNS_DIR      = ROOT / \"runs\" / \"phase2\" / RUN_TAG   # experiment run directory\n",
    "OUT_IMG_DIR   = RUNS_DIR / \"annotated\"               # annotated JPGs\n",
    "OUT_CSV_DIR   = RUNS_DIR / \"csv\"                     # detection CSVs\n",
    "FIG_DIR       = ROOT / \"reports\" / \"figures\" / RUN_TAG  # plots and visualizations\n",
    "\n",
    "# make sure all exist\n",
    "for p in [DATA_DIR, DERIVED_DIR, RUNS_DIR, OUT_IMG_DIR, OUT_CSV_DIR, FIG_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----- dataset source -----\n",
    "# Option A: use existing local dataset (preferred for speed)\n",
    "# Option B: use Roboflow if you want an on-demand cloud dataset\n",
    "USE_ROBOFLOW = True\n",
    "\n",
    "if not USE_ROBOFLOW:\n",
    "    # Use your derived/caltech_yolo images folder\n",
    "    DATA_IMG_DIR = DERIVED_DIR / \"images\" / \"test\"\n",
    "else:\n",
    "    # Roboflow download (expects env var ROBOFLOW_API_KEY)\n",
    "    from roboflow import Roboflow\n",
    "\n",
    "    api_key = os.environ.get(\"ROBOFLOW_API_KEY\")\n",
    "    assert api_key, \"Set ROBOFLOW_API_KEY in environment to download dataset securely.\"\n",
    "\n",
    "    rf = Roboflow(api_key=api_key)\n",
    "    project  = rf.workspace(\"raditya\").project(\"caltech-pedestrian-iitp\")\n",
    "    version  = project.version(1)\n",
    "    ds       = version.download(\"yolov11\")   # YOLOv11 format images\n",
    "\n",
    "    # try to find a valid split\n",
    "    candidates = [\n",
    "        Path(ds.location) / \"valid\" / \"images\",\n",
    "        Path(ds.location) / \"test\" / \"images\",\n",
    "        Path(ds.location) / \"train\" / \"images\",\n",
    "        Path(ds.location) / \"images\",   # fallback\n",
    "    ]\n",
    "    DATA_IMG_DIR = next((c for c in candidates if c.exists()), None)\n",
    "    assert DATA_IMG_DIR and any(DATA_IMG_DIR.glob(\"*.jpg\")), f\"No images found under {ds.location}\"\n",
    "\n",
    "print(f\"\\nâœ… Directory Structure:\")\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"DERIVED_DIR:\", DERIVED_DIR)\n",
    "print(\"RUNS_DIR:\", RUNS_DIR)\n",
    "print(\"FIG_DIR:\", FIG_DIR)\n",
    "print(\"Images dir:\", DATA_IMG_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e4fbf5-5757-4e21-978f-de9e2b602236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Load Pretrained Models from Ultralytics Hub\n",
    "# (no local .pt weights needed)\n",
    "# ============================================\n",
    "\n",
    "print(\"Loading models from Ultralytics Hub...\")\n",
    "\n",
    "# Load directly from Ultralytics registry\n",
    "yolo_model   = YOLO(\"yolov8n.pt\")    # baseline YOLOv8n\n",
    "rtdetr_model = YOLO(\"rtdetr-l.pt\")   # RT-DETR Large (Ultralytics implementation)\n",
    "\n",
    "print(\"Models loaded successfully.\")\n",
    "print(f\"YOLO device: {yolo_model.device}\")\n",
    "print(f\"RT-DETR device: {rtdetr_model.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d5195-a7af-40c0-851f-101fda5ba45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Run Inference on Dataset (YOLOv8n & RT-DETR-L)\n",
    "# ============================================\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# quick sanity check\n",
    "assert DATA_IMG_DIR.exists(), f\"Dataset path not found: {DATA_IMG_DIR}\"\n",
    "image_files = sorted([p for p in DATA_IMG_DIR.glob(\"*.jpg\")])\n",
    "if MAX_IMAGES:\n",
    "    image_files = image_files[:MAX_IMAGES]\n",
    "\n",
    "print(f\"ðŸ–¼ï¸ Found {len(image_files)} images for inference in {DATA_IMG_DIR}\")\n",
    "\n",
    "# unified inference settings\n",
    "predict_kwargs = dict(\n",
    "    imgsz=IMG_SIZE,\n",
    "    conf=CONF_THRESH,\n",
    "    save=True,\n",
    "    save_txt=True,\n",
    "    save_conf=True,\n",
    "    project=str(OUT_IMG_DIR),\n",
    "    name=\"predictions\",\n",
    "    exist_ok=True,\n",
    "    verbose=False\n",
    ")\n",
    "if PERSON_ONLY:\n",
    "    predict_kwargs[\"classes\"] = [0]  # COCO 'person'\n",
    "\n",
    "# helper function for single model inference\n",
    "def run_inference(model, model_name):\n",
    "    \"\"\"Run inference on all images and return a detections DataFrame.\"\"\"\n",
    "    rows = []\n",
    "    print(f\"\\nðŸš€ Running inference with {model_name}...\")\n",
    "\n",
    "    for img_path in tqdm(image_files, desc=model_name):\n",
    "        results = model(img_path, **predict_kwargs, stream=False)\n",
    "        res = results[0]\n",
    "\n",
    "        h, w = res.orig_shape\n",
    "        inf_ms = float(res.speed.get(\"inference\", 0.0)) if hasattr(res, \"speed\") else 0.0\n",
    "\n",
    "        for b in res.boxes:\n",
    "            cls_id = int(b.cls)\n",
    "            conf = float(b.conf)\n",
    "            x1, y1, x2, y2 = map(float, b.xyxy[0].tolist())\n",
    "\n",
    "            rows.append({\n",
    "                \"image_path\": str(img_path),\n",
    "                \"model\": model_name,\n",
    "                \"class_id\": cls_id,\n",
    "                \"class_name\": model.names.get(cls_id, str(cls_id)),\n",
    "                \"conf\": conf,\n",
    "                \"x1\": x1, \"y1\": y1, \"x2\": x2, \"y2\": y2,\n",
    "                \"width\": w, \"height\": h,\n",
    "                \"inf_ms\": inf_ms\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    print(f\"âœ… {model_name}: {len(df)} detections saved.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---- Run both models ----\n",
    "df_yolo   = run_inference(yolo_model, \"YOLOv8n\")\n",
    "df_rtdetr = run_inference(rtdetr_model, \"RT-DETR-L\")\n",
    "\n",
    "# ---- Merge and save ----\n",
    "df_all = pd.concat([df_yolo, df_rtdetr], ignore_index=True)\n",
    "\n",
    "out_csv = OUT_CSV_DIR / \"phase2_detections.csv\"\n",
    "df_all.to_csv(out_csv, index=False)\n",
    "\n",
    "print(f\"\\nðŸ“¦ All detections saved to: {out_csv.resolve()}\")\n",
    "display(df_all.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0c8fd2-3d96-45ff-85b6-462656676758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_collect_csv(model, model_name, images, out_img_dir, out_csv_dir,\n",
    "                          img_size=640, conf=0.25, person_only=True):\n",
    "    out_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_csv_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # where Ultralytics will drop annotated images\n",
    "    u_project = out_img_dir\n",
    "    u_name    = f\"{model_name}_viz\"\n",
    "\n",
    "    predict_kwargs = dict(\n",
    "        imgsz=img_size,\n",
    "        conf=conf,\n",
    "        save=True,\n",
    "        save_txt=True,\n",
    "        save_conf=True,\n",
    "        project=str(u_project),\n",
    "        name=u_name,\n",
    "        exist_ok=True,\n",
    "        verbose=False,\n",
    "        stream=True\n",
    "    )\n",
    "    if person_only:\n",
    "        predict_kwargs[\"classes\"] = [0]  # COCO 'person'\n",
    "\n",
    "    rows = []\n",
    "    for res in model.predict(source=[str(p) for p in images], **predict_kwargs):\n",
    "        # per-image timing (ms)\n",
    "        inf_ms = float(getattr(res, \"speed\", {}).get(\"inference\", 0.0))\n",
    "        h, w   = res.orig_shape\n",
    "        img_p  = res.path\n",
    "        for b in res.boxes:\n",
    "            cls_id = int(b.cls)\n",
    "            conf   = float(b.conf)\n",
    "            x1, y1, x2, y2 = map(float, b.xyxy[0].tolist())\n",
    "            rows.append({\n",
    "                \"image_path\": img_p,\n",
    "                \"model\": model_name,\n",
    "                \"class_id\": cls_id,\n",
    "                \"class_name\": model.names.get(cls_id, str(cls_id)),\n",
    "                \"conf\": conf,\n",
    "                \"x1\": x1, \"y1\": y1, \"x2\": x2, \"y2\": y2,\n",
    "                \"width\": w, \"height\": h,\n",
    "                \"inf_ms\": inf_ms\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    out_csv = out_csv_dir / f\"{model_name}_detections.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"[{model_name}] boxes: {len(df)} | csv -> {out_csv}\")\n",
    "    return df, out_csv, u_project / u_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f1f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yolo,  csv_yolo,  yolo_run_dir  = run_model_collect_csv(\n",
    "    yolo_model, \"yolov8n\", images, OUT_IMG_DIR, OUT_CSV_DIR,\n",
    "    img_size=IMG_SIZE, conf=CONF_THRESH, person_only=PERSON_ONLY\n",
    ")\n",
    "\n",
    "df_rtd,   csv_rtd,   rtd_run_dir   = run_model_collect_csv(\n",
    "    rtdetr_model, \"rtdetr-l\", images, OUT_IMG_DIR, OUT_CSV_DIR,\n",
    "    img_size=IMG_SIZE, conf=CONF_THRESH, person_only=PERSON_ONLY\n",
    ")\n",
    "\n",
    "print(\"YOLO images dir:\", yolo_run_dir)\n",
    "print(\"RT-DETR images dir:\", rtd_run_dir)\n",
    "display(df_yolo.head(3))\n",
    "display(df_rtd.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51954fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, mean, stddev, first\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Phase2_Compare\").getOrCreate()\n",
    "print(\"âœ… Spark version:\", spark.version)\n",
    "\n",
    "sdf_yolo = spark.read.option(\"header\", True).csv(str(csv_yolo), inferSchema=True)\n",
    "sdf_rtd  = spark.read.option(\"header\", True).csv(str(csv_rtd),  inferSchema=True)\n",
    "\n",
    "# union both with consistent schema (already aligned)\n",
    "sdf_all = sdf_yolo.unionByName(sdf_rtd)\n",
    "sdf_all.cache()\n",
    "print(\"Rows total:\", sdf_all.count())\n",
    "sdf_all.printSchema()\n",
    "sdf_all.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall per-model summary\n",
    "summary = (sdf_all\n",
    "           .groupBy(\"model\")\n",
    "           .agg(\n",
    "               count(\"*\").alias(\"num_boxes\"),\n",
    "               mean(\"conf\").alias(\"avg_conf\"),\n",
    "               stddev(\"conf\").alias(\"std_conf\"),\n",
    "               mean(\"inf_ms\").alias(\"avg_inf_ms\")\n",
    "           ))\n",
    "summary.show()\n",
    "\n",
    "# detections per image (per model)\n",
    "per_img = (sdf_all\n",
    "           .groupBy(\"model\", \"image_path\")\n",
    "           .agg(\n",
    "               count(\"*\").alias(\"detections\"),\n",
    "               first(\"inf_ms\").alias(\"inf_ms\") # same value per image; take one\n",
    "           ))\n",
    "per_img.show(5)\n",
    "\n",
    "# save spark outputs for reuse\n",
    "AGG_DIR = RUNS_DIR / \"spark_out\"\n",
    "AGG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "summary.write.mode(\"overwrite\").parquet(str(AGG_DIR / \"summary.parquet\"))\n",
    "per_img.write.mode(\"overwrite\").parquet(str(AGG_DIR / \"per_image.parquet\"))\n",
    "print(\"Saved parquet to:\", AGG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d13395",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_summary = summary.toPandas().sort_values(\"model\")\n",
    "pdf_perimg  = per_img.toPandas()\n",
    "\n",
    "# simple sanity prints\n",
    "display(pdf_summary)\n",
    "display(pdf_perimg.head())\n",
    "\n",
    "# 1) avg confidence by model\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=\"model\", y=\"avg_conf\", data=pdf_summary)\n",
    "plt.title(\"Average detection confidence\")\n",
    "plt.ylabel(\"Avg confidence\")\n",
    "plt.xlabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"avg_conf_by_model.png\", dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# 2) avg per-image latency by model\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=\"model\", y=\"avg_inf_ms\", data=pdf_summary)\n",
    "plt.title(\"Average per-image inference time (ms)\")\n",
    "plt.ylabel(\"Avg inference (ms)\")\n",
    "plt.xlabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"avg_inf_ms_by_model.png\", dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# 3) detections per image distribution (overlayed)\n",
    "plt.figure(figsize=(7,4))\n",
    "for m, g in pdf_perimg.groupby(\"model\"):\n",
    "    sns.kdeplot(g[\"detections\"], label=m)\n",
    "plt.title(\"Detections per image (KDE)\")\n",
    "plt.xlabel(\"# detections\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"detections_per_image_kde.png\", dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# 4) confidence histogram (sample for scale)\n",
    "pdf_all = sdf_all.sample(fraction=0.25, seed=7).toPandas() if sdf_all.count() > 10000 else sdf_all.toPandas()\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.histplot(data=pdf_all, x=\"conf\", hue=\"model\", bins=30, stat=\"density\", element=\"step\", common_norm=False)\n",
    "plt.title(\"Confidence distribution\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"confidence_hist.png\", dpi=200)\n",
    "plt.show()\n",
    "\n",
    "print(\"Figures ->\", FIG_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e67ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "picked = []\n",
    "for model_name, run_dir in [(\"yolov8n\", yolo_run_dir), (\"rtdetr-l\", rtd_run_dir)]:\n",
    "    samples = sorted(run_dir.glob(\"*.jpg\"))[:3]\n",
    "    for s in samples:\n",
    "        dst = FIG_DIR / f\"{model_name}_{s.name}\"\n",
    "        shutil.copy2(s, dst)\n",
    "        picked.append(dst)\n",
    "\n",
    "print(\"Sample annotated images copied:\")\n",
    "for p in picked:\n",
    "    print(\" -\", p)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
