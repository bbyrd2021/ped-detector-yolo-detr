{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf4f14-539f-4e71-ac84-0d0e25fa15bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# core imports\n",
    "import os, time, json, glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac28f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Project Configuration\n",
    "# ============================================\n",
    "\n",
    "# ----- experiment configuration -----\n",
    "RUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "PERSON_ONLY = True             # keep only 'person' class (COCO id=0)\n",
    "IMG_SIZE     = 640\n",
    "CONF_THRESH  = 0.25\n",
    "MAX_IMAGES   = None            # set small int while testing (e.g., 100)\n",
    "\n",
    "# ----- directory structure -----\n",
    "ROOT = Path(__file__).resolve().parents[1] if \"__file__\" in globals() else Path.cwd().parents[0] \n",
    "os.chdir(ROOT)                          # current project root\n",
    "DATA_DIR      = ROOT / \"data\"                        # raw dataset directory\n",
    "DERIVED_DIR   = ROOT / \"derived\" / \"caltech_yolo\"    # derived local data\n",
    "RUNS_DIR      = ROOT / \"runs\" / \"phase2\" / RUN_TAG   # experiment run directory\n",
    "OUT_IMG_DIR   = RUNS_DIR / \"annotated\"               # annotated JPGs\n",
    "OUT_CSV_DIR   = RUNS_DIR / \"csv\"                     # detection CSVs\n",
    "FIG_DIR       = ROOT / \"reports\" / \"figures\" / RUN_TAG  # plots and visualizations\n",
    "\n",
    "# make sure all exist\n",
    "for p in [DATA_DIR, DERIVED_DIR, RUNS_DIR, OUT_IMG_DIR, OUT_CSV_DIR, FIG_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----- dataset source -----\n",
    "# Option A: use existing local dataset (preferred for speed)\n",
    "# Option B: use Roboflow if you want an on-demand cloud dataset\n",
    "USE_ROBOFLOW = True\n",
    "\n",
    "if not USE_ROBOFLOW:\n",
    "    # Use derived/caltech_yolo images folder\n",
    "    DATA_IMG_DIR = DERIVED_DIR / \"images\" / \"test\"\n",
    "else:\n",
    "    # Roboflow download (expects env var ROBOFLOW_API_KEY)\n",
    "    from roboflow import Roboflow\n",
    "\n",
    "    api_key = os.environ.get(\"ROBOFLOW_API_KEY\")\n",
    "    assert api_key, \"Set ROBOFLOW_API_KEY in environment to download dataset securely.\"\n",
    "\n",
    "    rf = Roboflow(api_key=api_key)\n",
    "    project  = rf.workspace(\"raditya\").project(\"caltech-pedestrian-iitp\")\n",
    "    version  = project.version(1)\n",
    "    ds       = version.download(\"yolov11\")   # YOLOv11 format images\n",
    "\n",
    "    # try to find a valid split\n",
    "    candidates = [\n",
    "        Path(ds.location) / \"valid\" / \"images\",\n",
    "        Path(ds.location) / \"test\" / \"images\",\n",
    "        Path(ds.location) / \"train\" / \"images\",\n",
    "        Path(ds.location) / \"images\",   # fallback\n",
    "    ]\n",
    "    DATA_IMG_DIR = next((c for c in candidates if c.exists()), None)\n",
    "    assert DATA_IMG_DIR and any(DATA_IMG_DIR.glob(\"*.jpg\")), f\"No images found under {ds.location}\"\n",
    "\n",
    "print(f\"\\n Directory Structure:\")\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"DERIVED_DIR:\", DERIVED_DIR)\n",
    "print(\"RUNS_DIR:\", RUNS_DIR)\n",
    "print(\"FIG_DIR:\", FIG_DIR)\n",
    "print(\"Images dir:\", DATA_IMG_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e4fbf5-5757-4e21-978f-de9e2b602236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Load Pretrained Models from Ultralytics Hub\n",
    "# (no local .pt weights needed)\n",
    "# ============================================\n",
    "\n",
    "print(\"Loading models from Ultralytics Hub...\")\n",
    "\n",
    "# Load directly from Ultralytics registry\n",
    "yolo_model   = YOLO(\"yolov11m.pt\")    # baseline \n",
    "rtdetr_model = YOLO(\"rtdetr-l.pt\")   # RT-DETR Large (Ultralytics implementation)\n",
    "\n",
    "print(\"Models loaded successfully.\")\n",
    "print(f\"YOLO device: {yolo_model.device}\")\n",
    "print(f\"RT-DETR device: {rtdetr_model.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d5195-a7af-40c0-851f-101fda5ba45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Run Inference on Dataset (YOLOv8n & RT-DETR-L)\n",
    "# ============================================\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# quick sanity check\n",
    "assert DATA_IMG_DIR.exists(), f\"Dataset path not found: {DATA_IMG_DIR}\"\n",
    "image_files = sorted([p for p in DATA_IMG_DIR.glob(\"*.jpg\")])\n",
    "if MAX_IMAGES:\n",
    "    image_files = image_files[:MAX_IMAGES]\n",
    "\n",
    "print(f\"üñºÔ∏è Found {len(image_files)} images for inference in {DATA_IMG_DIR}\")\n",
    "\n",
    "# unified inference settings\n",
    "predict_kwargs = dict(\n",
    "    imgsz=IMG_SIZE,\n",
    "    conf=CONF_THRESH,\n",
    "    save=True,\n",
    "    save_txt=True,\n",
    "    save_conf=True,\n",
    "    project=str(OUT_IMG_DIR),\n",
    "    name=\"predictions\",\n",
    "    exist_ok=True,\n",
    "    verbose=False\n",
    ")\n",
    "if PERSON_ONLY:\n",
    "    predict_kwargs[\"classes\"] = [0]  # COCO 'person'\n",
    "\n",
    "# helper function for single model inference\n",
    "def run_inference(model, model_name):\n",
    "    \"\"\"Run inference on all images and return a detections DataFrame.\"\"\"\n",
    "    rows = []\n",
    "    print(f\"\\nüöÄ Running inference with {model_name}...\")\n",
    "\n",
    "    for img_path in tqdm(image_files, desc=model_name):\n",
    "        results = model(img_path, **predict_kwargs, stream=False)\n",
    "        res = results[0]\n",
    "\n",
    "        h, w = res.orig_shape\n",
    "        inf_ms = float(res.speed.get(\"inference\", 0.0)) if hasattr(res, \"speed\") else 0.0\n",
    "\n",
    "        for b in res.boxes:\n",
    "            cls_id = int(b.cls)\n",
    "            conf = float(b.conf)\n",
    "            x1, y1, x2, y2 = map(float, b.xyxy[0].tolist())\n",
    "\n",
    "            rows.append({\n",
    "                \"image_path\": str(img_path),\n",
    "                \"model\": model_name,\n",
    "                \"class_id\": cls_id,\n",
    "                \"class_name\": model.names.get(cls_id, str(cls_id)),\n",
    "                \"conf\": conf,\n",
    "                \"x1\": x1, \"y1\": y1, \"x2\": x2, \"y2\": y2,\n",
    "                \"width\": w, \"height\": h,\n",
    "                \"inf_ms\": inf_ms\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    print(f\"‚úÖ {model_name}: {len(df)} detections saved.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---- Run both models ----\n",
    "df_yolo   = run_inference(yolo_model, \"YOLOv8n\")\n",
    "df_rtdetr = run_inference(rtdetr_model, \"RT-DETR-L\")\n",
    "\n",
    "# ---- Merge and save ----\n",
    "df_all = pd.concat([df_yolo, df_rtdetr], ignore_index=True)\n",
    "\n",
    "out_csv = OUT_CSV_DIR / \"phase2_detections.csv\"\n",
    "df_all.to_csv(out_csv, index=False)\n",
    "\n",
    "print(f\"\\nüì¶ All detections saved to: {out_csv.resolve()}\")\n",
    "display(df_all.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0c8fd2-3d96-45ff-85b6-462656676758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Spark: Load and Aggregate Detection Results\n",
    "# ============================================\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ---- Initialize Spark ----\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PedestrianDetectionPhase2\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark Session Started\")\n",
    "\n",
    "# ---- Load YOLO + RT-DETR detections ----\n",
    "csv_path = str(OUT_CSV_DIR / \"phase2_detections.csv\")\n",
    "df_spark = spark.read.csv(csv_path, header=True, inferSchema=True)\n",
    "print(f\"üìÇ Loaded detections from {csv_path}\")\n",
    "\n",
    "# ---- Aggregate Metrics ----\n",
    "summary = (\n",
    "    df_spark.groupBy(\"model\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"num_detections\"),\n",
    "        F.mean(\"conf\").alias(\"mean_confidence\"),\n",
    "        F.stddev(\"conf\").alias(\"std_confidence\"),\n",
    "        F.mean(\"inf_ms\").alias(\"mean_inference_ms\"),\n",
    "        F.min(\"inf_ms\").alias(\"min_inference_ms\"),\n",
    "        F.max(\"inf_ms\").alias(\"max_inference_ms\"),\n",
    "        F.countDistinct(\"image_path\").alias(\"num_images\")\n",
    "    )\n",
    "    .orderBy(\"model\")\n",
    ")\n",
    "\n",
    "summary_pd = summary.toPandas()\n",
    "display(summary_pd)\n",
    "\n",
    "# ---- Save Spark Summary ----\n",
    "summary_csv = OUT_CSV_DIR / \"phase2_summary.csv\"\n",
    "summary_pd.to_csv(summary_csv, index=False)\n",
    "print(f\"Summary saved to {summary_csv.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f061d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Visualization: YOLOv11m vs RT-DETR-L\n",
    "# ============================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ---- Load Spark summary output ----\n",
    "summary_csv = OUT_CSV_DIR / \"phase2_summary.csv\"\n",
    "df_summary = pd.read_csv(summary_csv)\n",
    "\n",
    "# ---- Visualization output dir ----\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Figures will be saved to:\", FIG_DIR.resolve())\n",
    "\n",
    "sns.set(style=\"whitegrid\", context=\"talk\", palette=\"tab10\")\n",
    "\n",
    "# ---------- 1Ô∏è‚É£ Confidence Distribution ----------\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=df_summary, x=\"model\", y=\"mean_confidence\", hue=\"model\", dodge=False)\n",
    "plt.title(\"Mean Detection Confidence by Model\")\n",
    "plt.ylabel(\"Mean Confidence\")\n",
    "plt.xlabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"confidence_comparison.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# ---------- 2Ô∏è‚É£ Inference Latency ----------\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=df_summary, x=\"model\", y=\"mean_inference_ms\", hue=\"model\", dodge=False)\n",
    "plt.title(\"Mean Inference Latency (ms) per Model\")\n",
    "plt.ylabel(\"Inference Time (ms)\")\n",
    "plt.xlabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"latency_comparison.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# ---------- 3Ô∏è‚É£ Detections per Image ----------\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=df_summary, x=\"model\", y=\"num_detections\", hue=\"model\", dodge=False)\n",
    "plt.title(\"Total Detections per Model\")\n",
    "plt.ylabel(\"Number of Detections\")\n",
    "plt.xlabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"detections_comparison.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# ---------- 4Ô∏è‚É£ Combined Summary Plot ----------\n",
    "fig, ax1 = plt.subplots(figsize=(8,5))\n",
    "sns.scatterplot(\n",
    "    data=df_summary,\n",
    "    x=\"mean_confidence\",\n",
    "    y=\"mean_inference_ms\",\n",
    "    size=\"num_detections\",\n",
    "    hue=\"model\",\n",
    "    ax=ax1,\n",
    "    sizes=(100, 500)\n",
    ")\n",
    "plt.title(\"Confidence vs. Latency Trade-off\")\n",
    "plt.xlabel(\"Mean Confidence\")\n",
    "plt.ylabel(\"Mean Inference Time (ms)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"confidence_vs_latency.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "print(\"Comparison visualizations generated successfully.\")\n",
    "print(f\"All figures saved to: {FIG_DIR.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9456171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Phase 2 - Report Packaging\n",
    "# ============================================\n",
    "\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "SUMMARY_DIR = ROOT / \"reports\" / \"phase2\" / \"summary\"\n",
    "SUMMARY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- copy top visualizations ----\n",
    "key_figs = [\n",
    "    FIG_DIR / \"confidence_comparison.png\",\n",
    "    FIG_DIR / \"latency_comparison.png\",\n",
    "    FIG_DIR / \"detections_comparison.png\",\n",
    "    FIG_DIR / \"confidence_vs_latency.png\",\n",
    "]\n",
    "\n",
    "for f in key_figs:\n",
    "    if f.exists():\n",
    "        shutil.copy2(f, SUMMARY_DIR / f.name)\n",
    "\n",
    "# ---- generate markdown summary ----\n",
    "markdown_summary = f\"\"\"# üö¶ Phase 2 Model Benchmark Summary\n",
    "**Date:** {datetime.now().strftime(\"%Y-%m-%d %H:%M\")}  \n",
    "**Models Compared:** YOLOv11m vs RT-DETR-L  \n",
    "**Dataset:** Caltech Pedestrian (IITP via Roboflow)\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Key Metrics\n",
    "| Model | Mean Confidence | Mean Latency (ms) | Detections |\n",
    "|:------|----------------:|------------------:|------------:|\n",
    "\"\"\"\n",
    "\n",
    "for _, row in df_summary.iterrows():\n",
    "    markdown_summary += f\"| {row['model']} | {row['mean_confidence']:.3f} | {row['mean_inference_ms']:.2f} | {row['num_detections']} |\\n\"\n",
    "\n",
    "markdown_summary += f\"\"\"\n",
    "\n",
    "---\n",
    "\n",
    "## üñºÔ∏è Visual Comparisons\n",
    "![Confidence Distribution](confidence_comparison.png)  \n",
    "![Latency Histogram](latency_comparison.png)  \n",
    "![Detections Comparison](detections_comparison.png)  \n",
    "![Confidence vs Latency](confidence_vs_latency.png)\n",
    "\n",
    "---\n",
    "\n",
    "### üßæ Summary Notes\n",
    "- **YOLOv11m** demonstrates balanced speed and accuracy, achieving competitive confidence scores with lower latency than transformer-based RT-DETR-L.  \n",
    "- **RT-DETR-L** excels in detection recall and robustness under complex backgrounds, though at a higher inference cost.  \n",
    "- Ideal trade-off model depends on deployment: real-time ‚Üí YOLOv11m; high-fidelity offline ‚Üí RT-DETR-L.  \n",
    "\n",
    "‚úÖ Figures and summary saved to: `{SUMMARY_DIR.resolve()}`\n",
    "\"\"\"\n",
    "\n",
    "# ---- save markdown file ----\n",
    "md_path = SUMMARY_DIR / \"phase2_summary.md\"\n",
    "with open(md_path, \"w\") as f:\n",
    "    f.write(markdown_summary)\n",
    "\n",
    "print(\"‚úÖ Phase 2 summary report exported successfully.\")\n",
    "print(f\"üìÑ Markdown summary: {md_path.resolve()}\")\n",
    "print(f\"üìÅ Figures copied to: {SUMMARY_DIR.resolve()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
